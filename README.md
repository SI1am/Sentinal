# Facial Expression Recognition System

A deep learning-based facial expression recognition system that can detect and classify human emotions in real-time using webcam input. The system is built using PyTorch and OpenCV, capable of recognizing 8 different emotions: angry, disgust, fear, happy, neutral, sad, surprise, and confused. The system now includes a web interface for easy interaction and camera control.

## Features

- Real-time emotion detection using webcam
- Support for 8 different emotions
- High accuracy on training data (94.92%)
- Real-time visualization with confidence scores
- Easy-to-use web interface
- Camera control (on/off functionality)
- Emotion history tracking
- Cross-platform compatibility

## System Requirements

- Python 3.13 or higher
- Webcam
- CUDA-capable GPU (recommended for faster inference)
- Sufficient RAM (8GB minimum recommended)

## Installation

1. Clone the repository:
```bash
git clone <repository-url>
cd facial-recognition
```

2. Install the required dependencies:
```bash
pip install -r requirements.txt
```

## Project Structure

```
facial-recognition/
â”œâ”€â”€ app.py                 # Flask web application
â”œâ”€â”€ emotion_detection.py   # Emotion detection module
â”œâ”€â”€ train_model.py        # Script for training the emotion recognition model
â”œâ”€â”€ scrape_images.py      # Script for collecting training data
â”œâ”€â”€ requirements.txt      # List of Python dependencies
â”œâ”€â”€ emotion_model.pth     # Trained model weights
â”œâ”€â”€ training_history.png  # Training progress visualization
â”œâ”€â”€ templates/           # Web interface templates
â”‚   â””â”€â”€ index.html      # Main web interface
â”œâ”€â”€ train/              # Training dataset directory
â””â”€â”€ test/               # Test dataset directory
```

## Technical Details

### Libraries and Their Purposes

1. **PyTorch (torch)**
   - Primary deep learning framework
   - Used for:
     - Neural network architecture implementation
     - GPU acceleration
     - Automatic differentiation
     - Model training and inference
   - Chosen over TensorFlow because:
     - More Pythonic and intuitive API
     - Better debugging capabilities
     - Dynamic computational graphs
     - Stronger community support for computer vision tasks

2. **OpenCV (cv2)**
   - Computer vision library
   - Used for:
     - Real-time video capture
     - Face detection using Haar Cascade Classifier
     - Image preprocessing and resizing
     - Color space conversions
   - Chosen because:
     - Fast and efficient image processing
     - Well-documented face detection algorithms
     - Cross-platform compatibility
     - Real-time performance

3. **NumPy**
   - Numerical computing library
   - Used for:
     - Array operations
     - Matrix manipulations
     - Data preprocessing
   - Chosen because:
     - Efficient array operations
     - Seamless integration with PyTorch
     - Memory-efficient data structures

4. **Matplotlib**
   - Visualization library
   - Used for:
     - Training history plotting
     - Real-time emotion visualization
     - Performance metrics visualization
   - Chosen because:
     - Interactive plotting capabilities
     - Customizable visualization options
     - Real-time update support

5. **scikit-learn**
   - Machine learning library
   - Used for:
     - Data preprocessing
     - Model evaluation metrics
     - Dataset splitting
   - Chosen because:
     - Comprehensive ML tools
     - Well-implemented evaluation metrics
     - Easy integration with other libraries

### Model Parameters

1. **Input Parameters**
   - Image size: 48x48 pixels
   - Color channels: 1 (grayscale)
   - Normalization: [-1, 1] range
   - Batch size: 32

2. **Network Architecture Parameters**
   - Convolutional Layers:
     - Layer 1: 32 filters, 3x3 kernel, stride 1
     - Layer 2: 64 filters, 3x3 kernel, stride 1
     - Layer 3: 128 filters, 3x3 kernel, stride 1
   - Pooling Layers:
     - MaxPooling with 2x2 kernel, stride 2
   - Dropout Rate: 0.5
   - Batch Normalization: Enabled
   - Activation Function: ReLU

3. **Training Parameters**
   - Optimizer: Adam
   - Learning Rate: 0.001
   - Loss Function: CrossEntropyLoss
   - Epochs: 50
   - Early Stopping: Enabled (patience=5)
   - Learning Rate Scheduler: ReduceLROnPlateau

4. **Face Detection Parameters**
   - Scale Factor: 1.1
   - Minimum Neighbors: 5
   - Minimum Face Size: 30x30 pixels
   - Detection Confidence Threshold: 0.5

### Performance Optimization Techniques

1. **Data Preprocessing**
   - Grayscale conversion for reduced computation
   - Histogram equalization for better contrast
   - Face alignment for consistent input
   - Data augmentation for improved generalization

2. **Model Optimization**
   - Batch normalization for faster training
   - Dropout for regularization
   - Learning rate scheduling
   - Early stopping to prevent overfitting

3. **Inference Optimization**
   - GPU acceleration when available
   - Batch processing for multiple faces
   - Efficient face detection algorithm
   - Optimized image preprocessing pipeline

## Usage

### Web Interface

1. Start the Flask application:
```bash
python app.py
```

2. Open your web browser and navigate to:
```
http://127.0.0.1:5000
```

3. The web interface provides:
   - Live video feed with emotion detection
   - Camera control buttons (on/off)
   - Emotion history tracking
   - Image capture functionality
   - Real-time updates every 5 seconds

4. Features:
   - Turn camera on/off with a single click
   - View emotion detection history
   - Capture and save specific moments
   - Responsive design for all devices
   - Professional Bootstrap-styled interface

### Real-time Emotion Detection (Command Line)

1. Run the emotion detection script:
```bash
python emotion_detection.py
```

2. The script will:
   - Open your webcam
   - Detect faces in real-time
   - Display the detected emotion and confidence score
   - Press 'q' to quit the application

### Training the Model

1. Prepare your dataset:
   - Organize images in the `train/` and `test/` directories
   - Each emotion should have its own subdirectory
   - Supported image formats: JPG, PNG

2. Train the model:
```bash
python train_model.py
```

3. The training script will:
   - Load and preprocess the dataset
   - Train the model for 50 epochs
   - Save the trained model as 'emotion_model.pth'
   - Generate training history plots

## Model Architecture

The system uses a custom CNN architecture (EmotionNet) with the following components:

- Input: 48x48 grayscale images
- Convolutional layers with ReLU activation and batch normalization
- Max pooling layers
- Dropout for regularization
- Fully connected layers
- Output: 8 emotion classes

## Performance Metrics

- Training Accuracy: 94.92%
- Validation Accuracy: 57.54%
- Training Loss: 0.1579
- Validation Loss: 3.2510

## Dependencies

- PyTorch
- OpenCV
- NumPy
- Matplotlib
- scikit-learn
- tqdm
- Flask
- Pillow

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Acknowledgments

- FER2013 dataset for providing the base training data
- PyTorch community for the deep learning framework
- OpenCV community for computer vision tools

## Future Improvements

1. Data Augmentation
   - Implement more augmentation techniques
   - Add synthetic data generation

2. Model Architecture
   - Experiment with different architectures
   - Add attention mechanisms
   - Implement transfer learning

3. Performance Optimization
   - Reduce overfitting
   - Improve validation accuracy
   - Optimize inference speed

4. Additional Features
   - Support for video file input
   - Batch processing capabilities
   - API integration
   - Mobile deployment 



   

   # ğŸ˜Š My Magic Emotion Camera! ğŸ¥

Hello there! Welcome to our super cool project that can tell how you're feeling just by looking at your face! It's like having a friend who can read your emotions through your computer's camera. Isn't that amazing? 

## ğŸŒŸ What Does It Do?

Imagine having a magical mirror that can tell if you're:
- ğŸ˜  Angry
- ğŸ¤¢ Disgusted
- ğŸ˜¨ Scared (Fear)
- ğŸ˜Š Happy
- ğŸ˜ Neutral (Normal face)
- ğŸ˜¢ Sad
- ğŸ˜² Surprised
- ğŸ¤” Confused

Our special camera can do just that! It's like having a super-smart friend who can understand how you're feeling just by looking at your face!

## ğŸ® How to Use It

### What You Need First:
1. A computer ğŸ’»
2. A camera (webcam) ğŸ“¸
3. Python (a special computer language) ğŸ
4. Some special helper programs (we call them packages) ğŸ“¦

### Easy Steps to Get Started:
1. First, we need to install our helper programs:
```bash
pip install -r requirements.txt
```

2. To start the magic camera:
```bash
python emotion_detection.py
```

3. When it starts:
   - You'll see yourself on the screen! ğŸ“º
   - A blue box will appear around your face ğŸŸ¦
   - Above the box, you'll see what emotion it thinks you're showing
   - It also shows how sure it is about its guess (we call this confidence)

4. To stop the program:
   - Just press the 'q' key on your keyboard âŒ¨ï¸
   - The window will close, and the program will stop

## ğŸ¨ Fun Things to Try:

1. Make different faces and see if it can guess them right:
   - Try a big smile ğŸ˜Š
   - Make a surprised face ğŸ˜²
   - Pretend to be angry ğŸ˜ 
   - Look confused ğŸ¤”

2. Play with friends:
   - Take turns making faces
   - See who can get the highest confidence score
   - Try to trick the camera!

## ğŸ§  How Does It Work?

Imagine teaching a friend to recognize different types of fruit. You'd show them lots of apples, oranges, and bananas until they could tell them apart. Our program learned the same way!

1. **Learning Phase** (Training):
   - We showed it thousands of pictures of faces
   - Each picture was labeled with the correct emotion
   - The program learned patterns for each emotion
   - Just like learning that apples are round and red!

2. **Recognition Phase** (Detection):
   - The camera takes pictures of your face
   - The program looks for patterns it learned
   - It makes its best guess about your emotion
   - It's like a game of matching patterns!

## ğŸ“Š How Well Does It Work?

Our emotion detector is pretty good, but not perfect (just like humans!):
- It can correctly guess emotions about 67% of the time
- That means if it looks at 100 faces, it gets about 67 right
- Some emotions are easier to detect than others
- It works best with clear facial expressions and good lighting

## ğŸŒˆ Cool Facts About Our Project:

1. **Smart Learning**: 
   - Our program learned from over 49,000 different face pictures!
   - That's like looking at every student in 50 big schools!

2. **Fast Detection**:
   - It can guess your emotion in less than a second
   - That's faster than you can say "cheese" for a photo! ğŸ“¸

3. **Memory Power**:
   - It remembers patterns from all the faces it learned from
   - Just like how you remember what your friends look like!

## ğŸš€ Future Improvements

We want to make our emotion detector even better! Here's what we're planning:
1. Make it recognize more emotions
2. Make it work better in dark rooms
3. Add fun filters and effects
4. Make it work on phones and tablets

## ğŸ“ Learning Corner

Want to learn more? Here are some fun facts about emotions:
- Humans can make over 10,000 different facial expressions!
- Smiling is contagious - when you smile, others often smile back
- People all around the world show emotions in similar ways
- Your face has 43 muscles to make different expressions

## ğŸ¤ Need Help?

If something's not working:
1. Make sure your camera is turned on
2. Check that you have good lighting
3. Try sitting still and facing the camera
4. Ask a grown-up to help you run the program

## ğŸŒŸ Special Thanks

A big thank you to:
- All the scientists who helped create this technology
- The people who shared their face pictures for training
- Everyone who helped test and improve the program
- YOU for trying out our emotion detector! 

Remember: This is just for fun! Sometimes the program might make mistakes, just like we all do. The most important thing is to have fun while using it! ğŸ˜Š

## ğŸ¨ Colors and What They Mean

In our program:
- Blue Box: Shows where your face is
- White Text: Shows what emotion it detected
- Percentage: Shows how sure the program is about its guess

## ğŸ® Fun Game Ideas

1. **Emotion Charades**:
   - One person acts out an emotion
   - See if the computer can guess it
   - Keep score of right guesses!

2. **Emotion Race**:
   - Make a list of emotions
   - See who can get the computer to recognize them fastest
   - Take turns and time each player

3. **Mirror Mirror**:
   - Try to copy the emotion the computer detected
   - See if you can make it change its guess
   - Practice different expressions!

Stay happy and keep smiling! ğŸ˜Š 